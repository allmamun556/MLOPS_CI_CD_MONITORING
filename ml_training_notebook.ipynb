{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "# Related third-party imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import (AdaBoostRegressor, GradientBoostingRegressor, \n",
    "                              RandomForestRegressor)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, \n",
    "                             r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, LSTM, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://dagshub.com/allmamun556/MLOPS_CI_CD_MONITORING.mlflow\")\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'allmamun556'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'e93226059eb069c73f4c2738187b0a881fb403fa'\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = os.getenv('MLFLOW_TRACKING_USERNAME')\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = os.getenv('MLFLOW_TRACKING_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file, suppresses warnings, and returns the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The loaded data as a DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('data/Turbine_Data.csv')\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0': 'Time'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ControlBoxTemperature', 'WTG'], inplace=True)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.drop(columns='Time').notna().sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.drop(columns='Time').corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", \n",
    "            square=True, cbar_kws={\"shrink\": .8}, linewidths=0.5)\n",
    "\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns='GeneratorWinding2Temperature', inplace=True)\n",
    "df.drop(columns='GearboxBearingTemperature', inplace=True)\n",
    "df.drop(columns='RotorRPM', inplace=True)\n",
    "df.drop(columns=['Blade2PitchAngle', 'Blade3PitchAngle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New DataFrame Shape:\", df.shape)\n",
    "print(\"Remaining Columns:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = df.drop(columns=['Time']).corr()\n",
    "correlation_limit = 0.3 \n",
    "low_correlation_vars = correlation_matrix[correlation_matrix['ActivePower'].abs() < correlation_limit].index.tolist()\n",
    "if 'ActivePower' in low_correlation_vars:\n",
    "    low_correlation_vars.remove('ActivePower')  \n",
    "\n",
    "df.drop(columns=low_correlation_vars, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.drop(columns=['Time']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True,fmt=\".2f\")\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['ActivePower', 'BearingShaftTemperature', 'Blade1PitchAngle', \n",
    "             'GearboxOilTemperature', 'GeneratorRPM', 'GeneratorWinding1Temperature',\n",
    "             'HubTemperature', 'ReactivePower', 'WindSpeed']\n",
    "\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[var].dropna(), bins=40, kde=True, color='teal')\n",
    "    plt.title(f'Histograma de {var}')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df[var], color='teal')\n",
    "    plt.title(f'Boxplot de {var}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df[variables].describe().T[['mean', '50%', 'std']]\n",
    "stats.columns = ['Mean', 'Median', 'Std Dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    Q1 = df[var].quantile(0.25)\n",
    "    Q3 = df[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[var] < lower_bound) | (df[var] > upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ActivePower'].fillna(df['ActivePower'].interpolate(method='linear'), inplace=True)\n",
    "\n",
    "\n",
    "df['BearingShaftTemperature'].fillna(df['BearingShaftTemperature'].median(), inplace=True)\n",
    "\n",
    "df['Blade1PitchAngle'].fillna(df['Blade1PitchAngle'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df['GearboxOilTemperature'].fillna(df['GearboxOilTemperature'].median(), inplace=True)\n",
    "\n",
    "df['GeneratorRPM'].fillna(df['GeneratorRPM'].median(), inplace=True)\n",
    "\n",
    "df['GeneratorWinding1Temperature'].fillna(df['GeneratorWinding1Temperature'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df['HubTemperature'].fillna(df['HubTemperature'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df['ReactivePower'].fillna(df['ReactivePower'].median(), inplace=True)\n",
    "\n",
    "df['WindSpeed'].fillna(df['WindSpeed'].median(), inplace=True)\n",
    "\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Stationarity\n",
    "\n",
    "# Augmented Dickey-Fuller (ADF) Test\n",
    "result = adfuller(df['ActivePower'])\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "#KPSS Test\n",
    "kpss_statistic, p_value, _, critical_values = kpss(df['ActivePower'])\n",
    "print('KPSS Statistic:', kpss_statistic)\n",
    "print('p-value:', p_value)\n",
    "print('Critical Values:', critical_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying differentiation to the 'ActivePower' column\n",
    "\n",
    "df['active_power_diff'] = df['ActivePower'].diff().dropna()\n",
    "\n",
    "# Performing the ADF (Augmented Dickey-Fuller) test on the differenced series\n",
    "# The ADF test checks for stationarity in the time series data.\n",
    "result_adf = adfuller(df['active_power_diff'].dropna())\n",
    "\n",
    "# Printing the ADF statistic and p-value for the differenced series\n",
    "\n",
    "print('ADF Statistic (Differenced):', result_adf[0])\n",
    "print('p-value (Differenced):', result_adf[1])\n",
    "\n",
    "# Performing the KPSS (Kwiatkowski-Phillips-Schmidt-Shin) test on the differenced series\n",
    "# The KPSS test also checks for stationarity but has the null hypothesis that the series is stationary.\n",
    "kpss_statistic, p_value, _, critical_values = kpss(df['active_power_diff'].dropna())\n",
    "\n",
    "# Printing the KPSS statistic and p-value for the differenced series\n",
    "\n",
    "print('KPSS Statistic (Differenced):', kpss_statistic)\n",
    "print('p-value (Differenced):', p_value)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plotting the differenced active power data\n",
    "plt.plot(df['active_power_diff'], label='Differenced Active Power', color='green')\n",
    "plt.title('Differenced Active Power')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Differenced Active Power')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **a) Fitting the ARIMA model**\n",
    "data= df\n",
    "df['active_power_diff'].fillna(df['active_power_diff'].mean(), inplace=True)\n",
    "\n",
    "model_arima = ARIMA(df['active_power_diff'].dropna(), order=(1, 1, 2))\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# **b) Fitting the Exponential Smoothing model**\n",
    "model_exp = ExponentialSmoothing(df['active_power_diff'].dropna(), trend='add', seasonal='add', seasonal_periods=12)\n",
    "model_exp_fit = model_exp.fit()\n",
    "\n",
    "# **c) Preparing data for other models**\n",
    "df.to_csv('deepnn.csv')\n",
    "\n",
    "X = df.drop(columns=['ActivePower', 'Time'])\n",
    "y = df['ActivePower']\n",
    "\n",
    "# Removing NaNs\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# **d) Fitting the Random Forest model**\n",
    "model_rf = RandomForestRegressor(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# **e) Fitting the Decision Tree model**\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# **f) Fitting the AdaBoost model**\n",
    "model_ada = AdaBoostRegressor(n_estimators=100)\n",
    "model_ada.fit(X_train, y_train)\n",
    "y_pred_ada = model_ada.predict(X_test)\n",
    "\n",
    "# **g) Fitting the Gradient Boosting model**\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100)\n",
    "model_gb.fit(X_train, y_train)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "# **i) Fitting the ANN model**\n",
    "model_ann = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "model_ann.fit(X_train, y_train)\n",
    "y_pred_ann = model_ann.predict(X_test)\n",
    "\n",
    "# **m) Fitting the Polynomial Regression model**\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_poly_train, y_train)\n",
    "y_pred_poly = model_poly.predict(X_poly_test)\n",
    "\n",
    "# **n) Fitting the Linear Regression model**\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# **o) Making predictions for ARIMA and Exponential Smoothing**\n",
    "y_pred_arima = model_arima_fit.forecast(steps=len(y_test))\n",
    "y_pred_exp = model_exp_fit.forecast(steps=len(y_test))\n",
    "\n",
    "# **RNN, LSTM, CNN Models - with scaled and sequential data preparation**\n",
    "\n",
    "# Load your dataset and fill missing values in 'active_power_diff'\n",
    "#df_cleaned = data.drop(columns=['Unnamed: 0'])\n",
    "df['active_power_diff'].fillna(df['active_power_diff'].mean(), inplace=True)\n",
    "\n",
    "# Dropping 'Time' column\n",
    "df = df.drop(columns=['Time'])\n",
    "\n",
    "# Define the target and features\n",
    "X = df.drop(columns=['ActivePower'])\n",
    "y = df['ActivePower']\n",
    "\n",
    "# Normalize the data using MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Define the sequence length (timesteps)\n",
    "sequence_length = 10\n",
    "X_seq, y_seq = [], []\n",
    "\n",
    "# Creating sequences for model input\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X_seq.append(X_scaled[i:i+sequence_length])\n",
    "    y_seq.append(y_scaled[i+sequence_length])\n",
    "\n",
    "X_seq = np.array(X_seq, dtype=np.float64)\n",
    "y_seq = np.array(y_seq, dtype=np.float64)\n",
    "\n",
    "# Train-test split for sequential models\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# **r) Fitting the RNN model**\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_rnn.add(Dense(1))\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_rnn = model_rnn.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using RNN\n",
    "y_pred_rnn = model_rnn.predict(X_test_seq)\n",
    "y_pred_actual_rnn = scaler_y.inverse_transform(y_pred_rnn)\n",
    "y_test_actual_rnn = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **s) Fitting the LSTM model**\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_lstm = model_lstm.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using LSTM\n",
    "y_pred_lstm = model_lstm.predict(X_test_seq)\n",
    "y_pred_actual_lstm = scaler_y.inverse_transform(y_pred_lstm)\n",
    "y_test_actual_lstm = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **t) Fitting the CNN model**\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(50, activation='relu'))\n",
    "model_cnn.add(Dense(1))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_cnn = model_cnn.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using CNN\n",
    "y_pred_cnn = model_cnn.predict(X_test_seq)\n",
    "y_pred_actual_cnn = scaler_y.inverse_transform(y_pred_cnn)\n",
    "y_test_actual_cnn = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **p) Evaluation - Calculating RMSE for each model**\n",
    "\n",
    "# RMSE for ARIMA and Exponential Smoothing\n",
    "rmse_arima = mean_squared_error(y_test, y_pred_arima, squared=False)\n",
    "rmse_exp = mean_squared_error(y_test, y_pred_exp, squared=False)\n",
    "\n",
    "# RMSE for other models\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "rmse_dt = mean_squared_error(y_test, y_pred_dt, squared=False)\n",
    "rmse_ada = mean_squared_error(y_test, y_pred_ada, squared=False)\n",
    "rmse_gb = mean_squared_error(y_test, y_pred_gb, squared=False)\n",
    "rmse_ann = mean_squared_error(y_test, y_pred_ann, squared=False)\n",
    "rmse_poly = mean_squared_error(y_test, y_pred_poly, squared=False)\n",
    "rmse_lr = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "\n",
    "# RMSE for RNN, LSTM, CNN\n",
    "mse_rnn = mean_squared_error(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "mae_rnn = mean_absolute_error(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "r2_rnn = r2_score(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "\n",
    "mse_lstm = mean_squared_error(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "mae_lstm = mean_absolute_error(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "r2_lstm = r2_score(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "\n",
    "mse_cnn = mean_squared_error(y_test_actual_cnn, y_pred_actual_cnn)\n",
    "mae_cnn = mean_absolute_error(y_test_actual_cnn, y_pred_actual_cnn)\n",
    "r2_cnn = r2_score(y_test_actual_cnn, y_pred_actual_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation <a name=\"model-evaluation\"></a>\n",
    "After building our models, we will evaluate their performance using various metrics. We will compare the predictions against the actual outcomes to determine how well our models are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and log error metrics and parameters\n",
    "def evaluate_model_with_mlflow(y_true, y_pred, model_name, params):\n",
    "    mae = mean_absolute_error(y_true, y_pred)  # Calculate Mean Absolute Error\n",
    "    mse = mean_squared_error(y_true, y_pred)   # Calculate Mean Squared Error\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)  # Calculate Root Mean Squared Error\n",
    "    r2 = r2_score(y_true, y_pred)              # Calculate R² Score\n",
    "\n",
    "    print(f\"{model_name} Performance:\")        # Print the model name\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\\n\")  # Print the metrics\n",
    "\n",
    "     # Write the metrics to a text file\n",
    "    with open(\"metrics.txt\", \"a\") as f:\n",
    "        f.write(f\"{model_name} Performance:\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"MSE\", mse)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "        if model_name==\"Random Forest\":\n",
    "            mlflow.sklearn.log_model(model_name, \"random_forest_model\")\n",
    "\n",
    "# Example of logging for each model:\n",
    "\n",
    "# 1. Logging for ARIMA model\n",
    "arima_params = {'p': 3, 'd': 1, 'q': 0}  # Replace these with your actual ARIMA params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_arima, \"ARIMA\", arima_params)\n",
    "\n",
    "# 2. Logging for Exponential Smoothing model\n",
    "exp_params = {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}  # Replace with your actual params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_exp, \"Exponential Smoothing\", exp_params)\n",
    "\n",
    "# 3. Logging for Random Forest model\n",
    "rf_params = {'n_estimators': 100, 'max_depth': 10}  # Replace with your actual RF params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_rf, \"Random Forest\", rf_params)\n",
    "\n",
    "# 1. Logging for Decision Tree model\n",
    "dt_params = {}  # No specific hyperparameters provided in the example\n",
    "evaluate_model_with_mlflow(y_test, y_pred_dt, \"Decision Tree\", dt_params)\n",
    "\n",
    "# 2. Logging for AdaBoost model\n",
    "ada_params = {'n_estimators': 100}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_ada, \"AdaBoost\", ada_params)\n",
    "\n",
    "# 3. Logging for Gradient Boosting model\n",
    "gb_params = {'n_estimators': 100}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_gb, \"Gradient Boosting\", gb_params)\n",
    "\n",
    "# 9. Logging for Polynomial Regression model\n",
    "poly_params = {'degree': 3}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_poly, \"Polynomial Regression\", poly_params)\n",
    "\n",
    "# 10. Logging for Linear Regression model\n",
    "lr_params = {}  # No specific hyperparameters for Linear Regression\n",
    "evaluate_model_with_mlflow(y_test, y_pred_lr, \"Linear Regression\", lr_params)\n",
    "\n",
    "# 4. Logging for CNN model\n",
    "cnn_params = {'filters': 64, 'kernel_size': 2}  # Replace these with the actual CNN parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_cnn, y_pred_actual_cnn, \"CNN\", cnn_params)\n",
    "\n",
    "# 5. Logging for ANN model\n",
    "ann_params = {'hidden_layer_sizes': (100, 50), 'max_iter': 500}  # Replace these with the actual ANN parameters\n",
    "evaluate_model_with_mlflow(y_test, y_pred_ann, \"ANN\", ann_params)\n",
    "\n",
    "# 6. Logging for RNN model\n",
    "rnn_params = {'layers': 50, 'activation': 'relu'}  # Replace these with the actual RNN parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_rnn, y_pred_actual_rnn, \"RNN\", rnn_params)\n",
    "\n",
    "# 7. Logging for LSTM model\n",
    "lstm_params = {'layers': 50, 'activation': 'relu'}  # Replace these with the actual LSTM parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_lstm, y_pred_actual_lstm, \"LSTM\", lstm_params)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 796750,
     "sourceId": 1367163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
