{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import (AdaBoostRegressor, GradientBoostingRegressor, \n",
    "                              RandomForestRegressor)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, \n",
    "                             r2_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, LSTM, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/allmamun556/MLOPS_CI_CD_MONITORING.mlflow\")\n",
    "\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'allmamun556'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '9fa2d7645d7e9f3b7d30e37916af5939cdea03c5'\n",
    "print(\"mamun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('data/Turbine_Data.csv')\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ControlBoxTemperature', 'WTG'], inplace=True)\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df[df.drop(columns='Time').notna().sum(axis=1) > 0]\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again the missing values\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_cleaned.drop(columns='Time').corr()\n",
    "print(\"Correlation Matrix:\\n\", correlation_matrix)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "            square=True, cbar_kws={\"shrink\": .8}, linewidths=0.5)\n",
    "\n",
    "plt.title('Correlation Matrix of Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original DataFrame Shape:\", df_cleaned.shape)\n",
    "df_cleaned.drop(columns='GeneratorWinding2Temperature', inplace=True)\n",
    "print(\"Removed 'GeneratorWinding2Temperature' due to high correlation with 'GeneratorWinding1Temperature'.\")\n",
    "\n",
    "\n",
    "df_cleaned.drop(columns='GearboxBearingTemperature', inplace=True)\n",
    "print(\"Removed 'GearboxBearingTemperature' due to high correlation with 'GearboxOilTemperature'.\")\n",
    "\n",
    "\n",
    "df_cleaned.drop(columns='RotorRPM', inplace=True)\n",
    "print(\"Removed 'RotorRPM' due to high correlation with 'GeneratorRPM'.\")\n",
    "\n",
    "\n",
    "df_cleaned.drop(columns=['Blade2PitchAngle', 'Blade3PitchAngle'], inplace=True)\n",
    "print(\"Removed 'Blade2PitchAngle' and 'Blade3PitchAngle' due to high correlation with 'Blade1PitchAngle'.\")\n",
    "\n",
    "print(\"New DataFrame Shape:\", df_cleaned.shape)\n",
    "\n",
    "print(\"Remaining Columns:\\n\", df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_cleaned.drop(columns=['Time']).corr()\n",
    "correlation_limit = 0.3 \n",
    "low_correlation_vars = correlation_matrix[correlation_matrix['ActivePower'].abs() < correlation_limit].index.tolist()\n",
    "if 'ActivePower' in low_correlation_vars:\n",
    "    low_correlation_vars.remove('ActivePower')  \n",
    "\n",
    "df_cleaned.drop(columns=low_correlation_vars, inplace=True)  \n",
    "print(\"Remaining columns after removing variables with low correlation:\")\n",
    "print(df_cleaned.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_cleaned.drop(columns=['Time']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['ActivePower', 'BearingShaftTemperature', 'Blade1PitchAngle', \n",
    "             'GearboxOilTemperature', 'GeneratorRPM', 'GeneratorWinding1Temperature',\n",
    "             'HubTemperature', 'ReactivePower', 'WindSpeed']\n",
    "\n",
    "for var in variables:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df_cleaned[var].dropna(), bins=30, kde=True)\n",
    "    plt.title(f'Histograma de {var}')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=df_cleaned[var])\n",
    "    plt.title(f'Boxplot de {var}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df_cleaned[variables].describe().T[['mean', '50%', 'std']]\n",
    "stats.columns = ['Mean', 'Median', 'Std Dev']\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    Q1 = df_cleaned[var].quantile(0.25)\n",
    "    Q3 = df_cleaned[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_cleaned[(df_cleaned[var] < lower_bound) | (df_cleaned[var] > upper_bound)]\n",
    "    print(f'Outliers em {var}:')\n",
    "    print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleaned['ActivePower'].fillna(df_cleaned['ActivePower'].interpolate(method='linear'), inplace=True)\n",
    "\n",
    "\n",
    "df_cleaned['BearingShaftTemperature'].fillna(df_cleaned['BearingShaftTemperature'].median(), inplace=True)\n",
    "\n",
    "df_cleaned['Blade1PitchAngle'].fillna(df_cleaned['Blade1PitchAngle'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df_cleaned['GearboxOilTemperature'].fillna(df_cleaned['GearboxOilTemperature'].median(), inplace=True)\n",
    "\n",
    "df_cleaned['GeneratorRPM'].fillna(df_cleaned['GeneratorRPM'].median(), inplace=True)\n",
    "\n",
    "df_cleaned['GeneratorWinding1Temperature'].fillna(df_cleaned['GeneratorWinding1Temperature'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df_cleaned['HubTemperature'].fillna(df_cleaned['HubTemperature'].median(), inplace=True)\n",
    "\n",
    "\n",
    "df_cleaned['ReactivePower'].fillna(df_cleaned['ReactivePower'].median(), inplace=True)\n",
    "\n",
    "df_cleaned['WindSpeed'].fillna(df_cleaned['WindSpeed'].median(), inplace=True)\n",
    "\n",
    "\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Stationarity\n",
    "\n",
    "# Augmented Dickey-Fuller (ADF) Test\n",
    "result = adfuller(df_cleaned['ActivePower'])\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "#KPSS Test\n",
    "kpss_statistic, p_value, _, critical_values = kpss(df_cleaned['ActivePower'])\n",
    "print('KPSS Statistic:', kpss_statistic)\n",
    "print('p-value:', p_value)\n",
    "print('Critical Values:', critical_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying differentiation to the 'ActivePower' column\n",
    "\n",
    "df_cleaned['active_power_diff'] = df_cleaned['ActivePower'].diff().dropna()\n",
    "\n",
    "# Performing the ADF (Augmented Dickey-Fuller) test on the differenced series\n",
    "# The ADF test checks for stationarity in the time series data.\n",
    "result_adf = adfuller(df_cleaned['active_power_diff'].dropna())\n",
    "\n",
    "# Printing the ADF statistic and p-value for the differenced series\n",
    "\n",
    "print('ADF Statistic (Differenced):', result_adf[0])\n",
    "print('p-value (Differenced):', result_adf[1])\n",
    "\n",
    "# Performing the KPSS (Kwiatkowski-Phillips-Schmidt-Shin) test on the differenced series\n",
    "# The KPSS test also checks for stationarity but has the null hypothesis that the series is stationary.\n",
    "kpss_statistic, p_value, _, critical_values = kpss(df_cleaned['active_power_diff'].dropna())\n",
    "\n",
    "# Printing the KPSS statistic and p-value for the differenced series\n",
    "\n",
    "print('KPSS Statistic (Differenced):', kpss_statistic)\n",
    "print('p-value (Differenced):', p_value)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plotting the differenced active power data\n",
    "plt.plot(df_cleaned['active_power_diff'], label='Differenced Active Power')\n",
    "plt.title('Differenced Active Power')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Differenced Active Power')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **a) Fitting the ARIMA model**\n",
    "#data = pd.read_csv('deepnn.csv')\n",
    "data= df_cleaned\n",
    "#df_cleaned = data.drop(columns=['Unnamed: 0'])\n",
    "df_cleaned['active_power_diff'].fillna(df_cleaned['active_power_diff'].mean(), inplace=True)\n",
    "\n",
    "model_arima = ARIMA(df_cleaned['active_power_diff'].dropna(), order=(1, 1, 2))\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# **b) Fitting the Exponential Smoothing model**\n",
    "model_exp = ExponentialSmoothing(df_cleaned['active_power_diff'].dropna(), trend='add', seasonal='add', seasonal_periods=12)\n",
    "model_exp_fit = model_exp.fit()\n",
    "\n",
    "# **c) Preparing data for other models**\n",
    "df_cleaned.to_csv('deepnn.csv')\n",
    "\n",
    "X = df_cleaned.drop(columns=['ActivePower', 'Time'])\n",
    "y = df_cleaned['ActivePower']\n",
    "\n",
    "# Removing NaNs\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# **d) Fitting the Random Forest model**\n",
    "model_rf = RandomForestRegressor(n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# **e) Fitting the Decision Tree model**\n",
    "model_dt = DecisionTreeRegressor()\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# **f) Fitting the AdaBoost model**\n",
    "model_ada = AdaBoostRegressor(n_estimators=100)\n",
    "model_ada.fit(X_train, y_train)\n",
    "y_pred_ada = model_ada.predict(X_test)\n",
    "\n",
    "# **g) Fitting the Gradient Boosting model**\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100)\n",
    "model_gb.fit(X_train, y_train)\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "# **i) Fitting the ANN model**\n",
    "model_ann = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "model_ann.fit(X_train, y_train)\n",
    "y_pred_ann = model_ann.predict(X_test)\n",
    "\n",
    "# **m) Fitting the Polynomial Regression model**\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_poly_train, y_train)\n",
    "y_pred_poly = model_poly.predict(X_poly_test)\n",
    "\n",
    "# **n) Fitting the Linear Regression model**\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# **o) Making predictions for ARIMA and Exponential Smoothing**\n",
    "y_pred_arima = model_arima_fit.forecast(steps=len(y_test))\n",
    "y_pred_exp = model_exp_fit.forecast(steps=len(y_test))\n",
    "\n",
    "# **RNN, LSTM, CNN Models - with scaled and sequential data preparation**\n",
    "\n",
    "# Load your dataset and fill missing values in 'active_power_diff'\n",
    "#df_cleaned = data.drop(columns=['Unnamed: 0'])\n",
    "df_cleaned['active_power_diff'].fillna(df_cleaned['active_power_diff'].mean(), inplace=True)\n",
    "\n",
    "# Dropping 'Time' column\n",
    "df_cleaned = df_cleaned.drop(columns=['Time'])\n",
    "\n",
    "# Define the target and features\n",
    "X = df_cleaned.drop(columns=['ActivePower'])\n",
    "y = df_cleaned['ActivePower']\n",
    "\n",
    "# Normalize the data using MinMaxScaler\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Define the sequence length (timesteps)\n",
    "sequence_length = 10\n",
    "X_seq, y_seq = [], []\n",
    "\n",
    "# Creating sequences for model input\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X_seq.append(X_scaled[i:i+sequence_length])\n",
    "    y_seq.append(y_scaled[i+sequence_length])\n",
    "\n",
    "X_seq = np.array(X_seq, dtype=np.float64)\n",
    "y_seq = np.array(y_seq, dtype=np.float64)\n",
    "\n",
    "# Train-test split for sequential models\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# **r) Fitting the RNN model**\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_rnn.add(Dense(1))\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_rnn = model_rnn.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using RNN\n",
    "y_pred_rnn = model_rnn.predict(X_test_seq)\n",
    "y_pred_actual_rnn = scaler_y.inverse_transform(y_pred_rnn)\n",
    "y_test_actual_rnn = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **s) Fitting the LSTM model**\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_lstm = model_lstm.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using LSTM\n",
    "y_pred_lstm = model_lstm.predict(X_test_seq)\n",
    "y_pred_actual_lstm = scaler_y.inverse_transform(y_pred_lstm)\n",
    "y_test_actual_lstm = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **t) Fitting the CNN model**\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(50, activation='relu'))\n",
    "model_cnn.add(Dense(1))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history_cnn = model_cnn.fit(X_train_seq, y_train_seq, epochs=2, batch_size=32, validation_data=(X_test_seq, y_test_seq), verbose=1)\n",
    "\n",
    "# Predict using CNN\n",
    "y_pred_cnn = model_cnn.predict(X_test_seq)\n",
    "y_pred_actual_cnn = scaler_y.inverse_transform(y_pred_cnn)\n",
    "y_test_actual_cnn = scaler_y.inverse_transform(y_test_seq)\n",
    "\n",
    "# **p) Evaluation - Calculating RMSE for each model**\n",
    "\n",
    "# RMSE for ARIMA and Exponential Smoothing\n",
    "rmse_arima = mean_squared_error(y_test, y_pred_arima, squared=False)\n",
    "rmse_exp = mean_squared_error(y_test, y_pred_exp, squared=False)\n",
    "\n",
    "# RMSE for other models\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "rmse_dt = mean_squared_error(y_test, y_pred_dt, squared=False)\n",
    "rmse_ada = mean_squared_error(y_test, y_pred_ada, squared=False)\n",
    "rmse_gb = mean_squared_error(y_test, y_pred_gb, squared=False)\n",
    "rmse_ann = mean_squared_error(y_test, y_pred_ann, squared=False)\n",
    "rmse_poly = mean_squared_error(y_test, y_pred_poly, squared=False)\n",
    "rmse_lr = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "\n",
    "# RMSE for RNN, LSTM, CNN\n",
    "mse_rnn = mean_squared_error(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "mae_rnn = mean_absolute_error(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "r2_rnn = r2_score(y_test_actual_rnn, y_pred_actual_rnn)\n",
    "\n",
    "mse_lstm = mean_squared_error(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "mae_lstm = mean_absolute_error(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "r2_lstm = r2_score(y_test_actual_lstm, y_pred_actual_lstm)\n",
    "\n",
    "mse_cnn = mean_squared_error(y_test_actual_cnn, y_pred_actual_cnn)\n",
    "mae_cnn = mean_absolute_error(y_test_actual_cnn, y_pred_actual_cnn)\n",
    "r2_cnn = r2_score(y_test_actual_cnn, y_pred_actual_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'random_forest_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model_rf, file)\n",
    "\n",
    "print(f\"Model saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature names during training\n",
    "print(\"Features during training:\", model_rf.feature_names_in_)\n",
    "\n",
    "# Check feature names during prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation <a name=\"model-evaluation\"></a>\n",
    "After building our models, we will evaluate their performance using various metrics. We will compare the predictions against the actual outcomes to determine how well our models are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and log error metrics and parameters\n",
    "def evaluate_model_with_mlflow(y_true, y_pred, model_name, params):\n",
    "    mae = mean_absolute_error(y_true, y_pred)  # Calculate Mean Absolute Error\n",
    "    mse = mean_squared_error(y_true, y_pred)   # Calculate Mean Squared Error\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)  # Calculate Root Mean Squared Error\n",
    "    r2 = r2_score(y_true, y_pred)              # Calculate R² Score\n",
    "\n",
    "    print(f\"{model_name} Performance:\")        # Print the model name\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\\n\")  # Print the metrics\n",
    "\n",
    "     # Write the metrics to a text file\n",
    "    with open(\"metrics.txt\", \"a\") as f:\n",
    "        f.write(f\"{model_name} Performance:\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"MSE\", mse)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "# Example of logging for each model:\n",
    "\n",
    "# 1. Logging for ARIMA model\n",
    "arima_params = {'p': 3, 'd': 1, 'q': 0}  # Replace these with your actual ARIMA params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_arima, \"ARIMA\", arima_params)\n",
    "\n",
    "# 2. Logging for Exponential Smoothing model\n",
    "exp_params = {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}  # Replace with your actual params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_exp, \"Exponential Smoothing\", exp_params)\n",
    "\n",
    "# 3. Logging for Random Forest model\n",
    "rf_params = {'n_estimators': 100, 'max_depth': 10}  # Replace with your actual RF params\n",
    "evaluate_model_with_mlflow(y_test, y_pred_rf, \"Random Forest\", rf_params)\n",
    "\n",
    "# 1. Logging for Decision Tree model\n",
    "dt_params = {}  # No specific hyperparameters provided in the example\n",
    "evaluate_model_with_mlflow(y_test, y_pred_dt, \"Decision Tree\", dt_params)\n",
    "\n",
    "# 2. Logging for AdaBoost model\n",
    "ada_params = {'n_estimators': 100}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_ada, \"AdaBoost\", ada_params)\n",
    "\n",
    "# 3. Logging for Gradient Boosting model\n",
    "gb_params = {'n_estimators': 100}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_gb, \"Gradient Boosting\", gb_params)\n",
    "\n",
    "# 9. Logging for Polynomial Regression model\n",
    "poly_params = {'degree': 3}\n",
    "evaluate_model_with_mlflow(y_test, y_pred_poly, \"Polynomial Regression\", poly_params)\n",
    "\n",
    "# 10. Logging for Linear Regression model\n",
    "lr_params = {}  # No specific hyperparameters for Linear Regression\n",
    "evaluate_model_with_mlflow(y_test, y_pred_lr, \"Linear Regression\", lr_params)\n",
    "\n",
    "# 4. Logging for CNN model\n",
    "cnn_params = {'filters': 64, 'kernel_size': 2}  # Replace these with the actual CNN parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_cnn, y_pred_actual_cnn, \"CNN\", cnn_params)\n",
    "\n",
    "# 5. Logging for ANN model\n",
    "ann_params = {'hidden_layer_sizes': (100, 50), 'max_iter': 500}  # Replace these with the actual ANN parameters\n",
    "evaluate_model_with_mlflow(y_test, y_pred_ann, \"ANN\", ann_params)\n",
    "\n",
    "# 6. Logging for RNN model\n",
    "rnn_params = {'layers': 50, 'activation': 'relu'}  # Replace these with the actual RNN parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_rnn, y_pred_actual_rnn, \"RNN\", rnn_params)\n",
    "\n",
    "# 7. Logging for LSTM model\n",
    "lstm_params = {'layers': 50, 'activation': 'relu'}  # Replace these with the actual LSTM parameters\n",
    "evaluate_model_with_mlflow(y_test_actual_lstm, y_pred_actual_lstm, \"LSTM\", lstm_params)\n",
    "\n",
    "\n",
    "\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "# import mlflow.tensorflow\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# from keras.models import Sequential\n",
    "\n",
    "# def log_mlflow_model(model_name, model, params, y_true, y_pred, model_type='sklearn'):\n",
    "#     \"\"\"\n",
    "#     Logs a model and its metrics to MLflow.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_name: Name of the model to log.\n",
    "#     - model: The model instance to log.\n",
    "#     - params: Parameters used for training the model.\n",
    "#     - y_true: Ground truth target values.\n",
    "#     - y_pred: Predicted target values.\n",
    "#     - model_type: Type of model ('sklearn', 'keras', 'tensorflow', 'statsmodels', etc.).\n",
    "#     \"\"\"\n",
    "#     # Calculate metrics\n",
    "#     mae = mean_absolute_error(y_true, y_pred)\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "#     # Start an MLflow run\n",
    "#     with mlflow.start_run(run_name=model_name):\n",
    "#         # Log parameters\n",
    "#         mlflow.log_params(params)\n",
    "\n",
    "#         # Log metrics\n",
    "#         mlflow.log_metric(\"MAE\", mae)\n",
    "#         mlflow.log_metric(\"MSE\", mse)\n",
    "#         mlflow.log_metric(\"RMSE\", rmse)\n",
    "#         mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "#         # Log the model\n",
    "#         if model_type == 'sklearn':\n",
    "#             mlflow.sklearn.log_model(model, \"model\")\n",
    "#         elif model_type == 'keras':\n",
    "#             mlflow.keras.log_model(model, \"model\")\n",
    "#         elif model_type == 'tensorflow':\n",
    "#             mlflow.tensorflow.log_model(model, \"model\")\n",
    "#         elif model_type == 'statsmodels':\n",
    "#             mlflow.statsmodels.log_model(model, \"model\")\n",
    "#         else:\n",
    "#             print(f\"Unsupported model type for {model_name}\")\n",
    "\n",
    "#         print(f\"Model '{model_name}' logged successfully.\\n\")\n",
    "\n",
    "# # Log ARIMA Model\n",
    "# params_arima = {'order': (1, 1, 2)}\n",
    "# log_mlflow_model(\"ARIMA\", model_arima_fit, params_arima, y_test, y_pred_arima, model_type='statsmodels')\n",
    "\n",
    "# # Log Exponential Smoothing Model\n",
    "# params_exp = {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}\n",
    "# log_mlflow_model(\"Exponential Smoothing\", model_exp_fit, params_exp, y_test, y_pred_exp, model_type='statsmodels')\n",
    "\n",
    "# # Log Random Forest\n",
    "# params_rf = {'n_estimators': 100}\n",
    "# log_mlflow_model(\"Random Forest\", model_rf, params_rf, y_test, y_pred_rf)\n",
    "\n",
    "# # Log Decision Tree\n",
    "# log_mlflow_model(\"Decision Tree\", model_dt, {}, y_test, y_pred_dt)\n",
    "\n",
    "# # Log AdaBoost\n",
    "# params_ada = {'n_estimators': 100}\n",
    "# log_mlflow_model(\"AdaBoost\", model_ada, params_ada, y_test, y_pred_ada)\n",
    "\n",
    "# # Log Gradient Boosting\n",
    "# params_gb = {'n_estimators': 100}\n",
    "# log_mlflow_model(\"Gradient Boosting\", model_gb, params_gb, y_test, y_pred_gb)\n",
    "\n",
    "# # Log ANN Model (MLPRegressor)\n",
    "# params_ann = {'hidden_layer_sizes': (100, 50), 'max_iter': 500, 'random_state': 42}\n",
    "# log_mlflow_model(\"Artificial Neural Network (ANN)\", model_ann, params_ann, y_test, y_pred_ann)\n",
    "\n",
    "# # Log Polynomial Regression\n",
    "# params_poly = {'degree': 3}\n",
    "# log_mlflow_model(\"Polynomial Regression\", model_poly, params_poly, y_test, y_pred_poly)\n",
    "\n",
    "# # Log Linear Regression\n",
    "# log_mlflow_model(\"Linear Regression\", model_lr, {}, y_test, y_pred_lr)\n",
    "\n",
    "# # Log RNN Model\n",
    "# params_rnn = {'layers': 'SimpleRNN', 'activation': 'relu', 'epochs': 2, 'batch_size': 32}\n",
    "# log_mlflow_model(\"RNN\", model_rnn, params_rnn, y_test_actual_rnn, y_pred_actual_rnn, model_type='keras')\n",
    "\n",
    "# # Log LSTM Model\n",
    "# params_lstm = {'layers': 'LSTM', 'activation': 'relu', 'epochs': 2, 'batch_size': 32}\n",
    "# log_mlflow_model(\"LSTM\", model_lstm, params_lstm, y_test_actual_lstm, y_pred_actual_lstm, model_type='keras')\n",
    "\n",
    "# # Log CNN Model\n",
    "# params_cnn = {'layers': 'Conv1D', 'filters': 64, 'kernel_size': 2, 'epochs': 2, 'batch_size': 32}\n",
    "# log_mlflow_model(\"CNN\", model_cnn, params_cnn, y_test_actual_cnn, y_pred_actual_cnn, model_type='keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Start your MLflow experiment as usual\n",
    "# mlflow.start_run()\n",
    "\n",
    "# # Track parameters, metrics, and artifacts as needed\n",
    "# mlflow.log_param(\"param_name\", param_value)\n",
    "# mlflow.log_metric(\"metric_name\", metric_value)\n",
    "\n",
    "# # Save models or artifacts\n",
    "# mlflow.log_artifact(\"path_to_artifact\")\n",
    "\n",
    "# # End the experiment\n",
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 796750,
     "sourceId": 1367163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
